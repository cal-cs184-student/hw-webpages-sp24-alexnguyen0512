<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184/284A Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184/284A: Computer Graphics and Imaging, Spring 2024</h1>
<h1 align="middle">Homework 1: Rasterizer</h1>
<h2 align="middle">Alex Nguyen</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>This homework explored the basic mechanism of graphics rasterization, transforms, and texture mapping by building
  a functional image parser that can render polygons with arbitrary shape and orientation, as well as map onto them
  custom textures/images.</p>
<p>
  The from-scratch implementation of rasterization really shows how the simple geometric logic of point sampling and
  line equation checks can be used to effincitly to render graphics on a grid of pixel. 
  The most interesting takeaway from this homework is the internalization of graphics as simply a connected host of
  data structure of color values and coordinates, and how flexible that implementation is to operations like
  linear transformations and upgrades like supersampling to combat aliasing.
</p>
<p>The biggest challenge of this project was to get used to C++ syntax and pointer logic again, but 
  once that review is done, the implementation was quite straight-forward by simply following the mathematical
  frameworks introduced in lecture.
</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
<p>Triangles are rasterized by sampling a grid of points and testing each points using the line 
  equation constructed from the triangles' vectices as described in lecture.
  If the sampled point is "above" all 3 edges of the triangle, that point is decidedly 
  inside the triangle and can be filled with the triangle's color value.
</p>
<p>To make sure our line equation tests are consistent, we need to establish a consistent winding
  order for the vertices. This is done by a quick line equation check before rasterization 
  and reordering the vertices so that they are ordered in a clockwise direction.
</p>
<p>Finally, to fill a pixel, one simply pass in the selcted fillcolor of the triangle into the framebuffer
  location associated with that pixel (as 3 float rgb values)
</p>
<p>To make sure the line equation checks are efficient and to eliminate uncessary samples,
  for each triangle, only the pixels within its bonding box are sampled. That is the box
  bounded by (min_x(vertices), min_y(vertices)), (min_x(vertices), max_y(vertices)),
  (max_x(vertices), min_y(vertices)), (max_x(vertices), max_y(vertices)), which can be used 
  to define the limits of the nested sampling loop.
</p>
<p>Here is the screenshot of some test redering of svg files in the svg/basic folder
  with the pixel inspector centered on a the sharpest edge in test 4, 
  showing signs of aliasing due to the fast changing signal.
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="assets/png/task1_test3.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 3 - default parameters</figcaption>
      </td>
      <td>
        <img src="assets/png/task1_test4.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 4 - default parameters</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="assets/png/task1_test5.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 5 - default parameters</figcaption>
      </td>
      <td>
        <img src="assets/png/task1_test6.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 6 - default parameters</figcaption>
      </td>
    </tr>
  </table>
</div>

<h3 align="middle">Part 2: Antialiasing triangles</h3>
<p>Supersampling is implemented by using an intermediary, higher-resolution sample buffer
  before rendering to the frame buffer. The sample buffer is sample_rate times larger than
  the frame buffer and stores sample_rate amount of values per frame pixel.
</p>
<p>Let s be our sample rate. For each pixel location in the frame, the algorithm sample at s 
  evenly spaced location within the pixel. This is implemented by a nested loop over sqrt(s) in each
  direction that dissect each pixel area into a sqrt(s) * sqrt(s) grid. The sampling method
  at each sub_grid location is the same as above, using line_equation checks and filling in the appropriate
  sample_buffer locations. 
</p>
<p>Here, each subgrid is also organized in the sample buffer in consecutive 1D arrays to make downsampling simpler.
  Before the values can be rendered to the (smaller) framebuffer, each subgrid need to be averaged into one color value
  per pixel. This is done by simply adding up each pixel's r, g, and b values in the subgrid and dividing by sample_rate.
</p>
<p>What this algorithm does is essentially increasing the rate of point sampling so that it can better capture fast changing
  signals like sharp edges and corners. As seen in the pixel inspector printout below, the sharp edge in test4 is 
  blurred when zoomed in, representing the sub_grid averaging that happens before rendering, and gives the impression of a cleaner
  line, with less jaggies.
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="assets/png/task1_test4.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 4 - default parameters</figcaption>
      </td>
      <td>
        <img src="assets/png/task2_test4_4.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 4 - 4x supersampling</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="assets/png/task2_test4_9.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 4 - 9x supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/task2_test4_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 4 - 16x supersampling</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 3: Transforms</h3>
<p>Transforms are done by defining a set of 3x3 matrixes that can scale, rotate, and translate
  homogeneous coordinates in our 2D space. The construction of these matrices follow basic linear
  algebra intuitions discussed in lecture.
</p>
<p>Below shows a rendering of a transformed image of the robot given for this task.
  Additional (hierachical) tranformation steps were added to the svg file to move the robots arms and 
  head to give the impression of a waving gesture, with one arm on the hip and a tilted head.
</p>
<div align="middle">
  <img src="assets/png/my_robot.png" align="middle" width="400px"/>
  <figcaption align="middle">Task 3 - Waving Blue Robot Wearing a Red Shirt</figcaption>  
</div>



<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>
<p>Barycentric coordinates describe the position of a coordinate relative to a set of vertices (in this case,
  those of the triangle in which the point lies). It's a degenerate coordinate system that encodes how far the point
  is from each vertex, thus naturally serves as weights for averaging the pixel values of the vertexes,
  providing a smoother alternative to simply choosing the nearest vertex.
  This allows for linear interpolation across
  triangles and consequently rendering of gradients as seen in test7 below.
</p>
<p>An additional triangle svg file was also generated to demonstrate the interpolation effect of using 
  barycentric coordinates. The relative r, g, and b values at each location literally represents its relative distance
  to the red, green, and blue vertices, respectively
</p>
<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="assets/png/barycentric.png" align="middle" width="400px"/>
        <figcaption align="middle">Triangle Interpolation Demo</figcaption>
      </td>
      <td>
        <img src="assets/png/task4_test7.png" align="middle" width="400px"/>
        <figcaption align="middle">Test 7- Barycentric Coordinates - Default Parameters</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
<p>Pixel sampling is done by mapping each pixel (x,y) location to a (u,v) coordinate in texture space.
  Because we need a smooth 1-to-1 mapping, the natural choice is to use the barycentric coordinates
  implemented in the last section to map each pixel location to the (weighted) average of the texel locations
  of its triangle's vertices.
</p>
<p>Once the texture coordinate is calculated, we need to sample the texture image at that location and map its
  color value back to the sample buffer. The two choices for that are nearest pixel sampling and bilinear sampling.
</p>
<p>In nearest pixel sampling, one simply rounds the float (u,v) coordinate to its closest interger texel locaiton
  and select that value for the mapping. When using bilinear sampling, one instead uses the same logic of barycentric
  coordinate to linearly interpolate between the nearst 4 texels, in this case, done with 3 lerp function calls.
  (2 calls to linearly interpolate in one direction and another to interpolate between those values to get interpolation in 2D)
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="assets/png/task5_nearest_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 5 - Nearest sampling, no supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/task5_nearest16.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 5 - Nearest sampling, 16x supersampling</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="assets/png/task5_bilinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 5 - Bilinear sampling, no supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/task5_bilinear_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 5 - Bilinear sampling, 16x supersampling</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>In the above grid, one can see the anti-aliasing power of bilinear sampling compared to nearst sampling.
  In the fast-changing signals around the campanile's windows nearst sampling has a hard time mapping the fine
  details without artifacts like jaggies around edges. Bilinear interpolation helps reduce these effects
  even without using the more memory-intesive method of super sampling.
</p>
<p>Just like supersampling, bilinear interpolation will show the most dramatic improvement over nearest sampling
  when there are very fast changing signals in the texture map. 
</p>


<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>
<p>Level sampling is idea of better matching the resolution of the texture map to the screen sampling rate 
  at each location in the frame to minimize texture footprints/aliasing. It essentially selects ths best 
  texture resolution at each location, and downsample when needed but not unneccessarily blur other spots. 
</p>
<p>This is done be storing different resolutions of the texture image in different levels known as mipmaps,
  and calculating the appropriate mipmap level at each sampling locations. The level are calculated by approximating
  the changing rate (derivative) of the texture signal at each location by calculating the discrete texel difference between
  surrounding pixel locations. The mipmap levels are then selected based on 2 different scheme, nearest level sampling or
  linear interpolation between nearest levels.
</p>
<p>With the three techniques of pixel sampling, level sampling, and supersampling, our renderer now has 
  multiple tools to combat aliasing artifacts. The most effective antialiasing technique is supersampling,
  as this fundamentally just increases the sampling rate accross the board to better high-frequency signals.
  However, it is also the most memmory intensive, as it requires the storage of a higher resolution sample buffer,
  which scales linearly with out sampling rate, in addition to the framebuffer.
</p>
<p>Bilinear interpolation offers a cheaper (in terms of memory) way to anti-aliase, at the cost of some additional
  texel access and lerp function calls. It works by essentially working as a low pass filter over the texture signal 
  before sampling, cutting out high-frequency, artifact-producing signals, without the need to increase sampling rate.
  While this is much more efficient, it provides less anti-aliasing power than supersampling.
</p>
<p>Level sampling takes a step further and adjust said filtering power and the texture resolution based on the local
  sampling rate of each pixel. This requires slightly more memory as it needs to store multiple copies of the texture
  in decreasing resolution and requires some additional texel reads and lerp calculation at sampling time. However,
  the mipmap data structure provides a quite space efficent ways to store the different levels. While still not as
  powerful as supersampling in terms of anti-aliasing power, mipmap sampling provides a much more efficient, and (for most cases),
  sufficient antiliasing technique in texture mapping.
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="assets/png/can_l0_pnearest_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_ZERO, P_NEAREST, no supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/can_l0_plinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_ZERO, P_LINEAR, no supersampling</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="assets/png/can_lnearest_pnearest_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_NEAREST, P_NEAREST, no supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/can_lnearest_plinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_NEAREST, P_LINEAR, no supersampling</figcaption>
      </td>
    </tr>
    <br>
    <tr>
      <td>
        <img src="assets/png/can_llinear_plinear_1.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_LINEAR, P_LINEAR, no supersampling</figcaption>
      </td>
      <td>
        <img src="assets/png/can_llinear_plinear_16.png" align="middle" width="400px"/>
        <figcaption align="middle">Task 6 - L_LINEAR, P_LINEAR, 16x supersampling</figcaption>
      </td>
    </tr>
  </table>
</div>

<p>This is a picture of my friend wearing a fur hat. I chose this picture because of the fine detailing
  in the fur strands, which when mapped with no special pixel/level sampling or supersampling method,
  produces noticable aliasing as seen in the top_left picure.
</p>
<p>The grid is ordered by increasing anti-aliasing power of the combinations of techniques used.
  One can see that linear pixel sampling on its one reduces the artifacts significantly, but not thoroughly.
  Adding on nearest level sampling again significantly improves the resolution of the strands of fur.
  By the time full trilinear sammpling is used, the quality of the image is almost comparable to 16x sampling,
  which does not improve the quality beyond that.
</p>


</body>
</html>
